{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10892821,"sourceType":"datasetVersion","datasetId":6769337}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:39:49.630414Z","iopub.execute_input":"2025-03-21T14:39:49.630702Z","iopub.status.idle":"2025-03-21T14:39:50.360126Z","shell.execute_reply.started":"2025-03-21T14:39:49.630670Z","shell.execute_reply":"2025-03-21T14:39:50.359238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install zstandard python-chess","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:39:50.361037Z","iopub.execute_input":"2025-03-21T14:39:50.361566Z","iopub.status.idle":"2025-03-21T14:39:58.063726Z","shell.execute_reply.started":"2025-03-21T14:39:50.361526Z","shell.execute_reply":"2025-03-21T14:39:58.062603Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Getting Data\nDecompressiing `.zst` compressed PGN (Portable Game Notation) file containing chess game, and read the first games from it.\n","metadata":{}},{"cell_type":"code","source":"import zstandard as zstd\nimport chess.pgn\nimport io\n\n# Define input file path\ninput_path = \"/kaggle/input/lichess-data-february-standard-rated-2025/lichess_db_standard_rated_2025-02.pgn.zst\"\n\n# Open the compressed file and stream decompress\nwith open(input_path, 'rb') as compressed_file:\n    dctx = zstd.ZstdDecompressor()\n    with dctx.stream_reader(compressed_file) as reader:\n        # Wrap decompressed stream with TextIOWrapper to behave like a file\n        text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n\n        # Read the first game\n        game = chess.pgn.read_game(text_stream)\n\n        if game:\n            print(game.headers)  # Print game metadata\n        else:\n            print(\"No games found in the PGN file!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:39:58.064885Z","iopub.execute_input":"2025-03-21T14:39:58.065152Z","iopub.status.idle":"2025-03-21T14:39:58.169187Z","shell.execute_reply.started":"2025-03-21T14:39:58.065124Z","shell.execute_reply":"2025-03-21T14:39:58.168489Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating Dataframe \n\nThis code extracts and loads chess game data from a compressed PGN file into a Pandas DataFrame, including player names, game result, opening, and moves. The data is ready for **Exploratory Data Analysis (EDA)**, where you can analyze player performance, popular openings, and game outcomes. Visualizations and statistical analysis can further explore trends in game results and move sequences.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ngames_data = []\ngame_count = 0\nmax_games = 10000  # Change this to read more games\n\nwith open(input_path, 'rb') as compressed_file:\n    dctx = zstd.ZstdDecompressor()\n    with dctx.stream_reader(compressed_file) as reader:\n        text_stream = io.TextIOWrapper(reader, encoding='utf-8')\n\n        while game_count < max_games:\n            game = chess.pgn.read_game(text_stream)\n            if game is None:\n                break  # No more games\n\n            games_data.append({\n                \"White\": game.headers.get(\"White\", \"\"),\n                \"Black\": game.headers.get(\"Black\", \"\"),\n                \"Result\": game.headers.get(\"Result\", \"\"),\n                \"ECO\": game.headers.get(\"ECO\", \"\"),\n                \"Opening\": game.headers.get(\"Opening\", \"\"),\n                \"Moves\": \" \".join(str(move) for move in game.mainline_moves())  # Convert moves to string\n            })\n            game_count += 1\n\nprint(f\"Loaded {len(games_data)} games into DataFrame.\")\n\n# Convert to DataFrame and display\ndf = pd.DataFrame(games_data)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:39:58.170940Z","iopub.execute_input":"2025-03-21T14:39:58.171157Z","iopub.status.idle":"2025-03-21T14:40:26.772402Z","shell.execute_reply.started":"2025-03-21T14:39:58.171138Z","shell.execute_reply":"2025-03-21T14:40:26.771453Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Inspecting Dataframe\n","metadata":{}},{"cell_type":"code","source":"df.head(100)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.776589Z","iopub.execute_input":"2025-03-21T14:40:26.776896Z","iopub.status.idle":"2025-03-21T14:40:26.805747Z","shell.execute_reply.started":"2025-03-21T14:40:26.776865Z","shell.execute_reply":"2025-03-21T14:40:26.805057Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail(100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.806468Z","iopub.execute_input":"2025-03-21T14:40:26.806691Z","iopub.status.idle":"2025-03-21T14:40:26.828577Z","shell.execute_reply.started":"2025-03-21T14:40:26.806673Z","shell.execute_reply":"2025-03-21T14:40:26.827706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.829546Z","iopub.execute_input":"2025-03-21T14:40:26.829824Z","iopub.status.idle":"2025-03-21T14:40:26.859742Z","shell.execute_reply.started":"2025-03-21T14:40:26.829793Z","shell.execute_reply":"2025-03-21T14:40:26.858942Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Cleaning Process\n\n1. **Unknown Openings**:\n   - Counts and prints the number of games with unknown openings (`\"?\"` in the \"Opening\" column).\n","metadata":{}},{"cell_type":"code","source":"unknown_openings_count = df[df[\"Opening\"] == \"?\"].shape[0]\nprint(f\"Games with unknown openings: {unknown_openings_count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.860482Z","iopub.execute_input":"2025-03-21T14:40:26.860707Z","iopub.status.idle":"2025-03-21T14:40:26.872152Z","shell.execute_reply.started":"2025-03-21T14:40:26.860677Z","shell.execute_reply":"2025-03-21T14:40:26.871389Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. **Short Move Games**:\n   - Counts and prints the number of games with fewer than 12 moves.\n","metadata":{}},{"cell_type":"code","source":"short_move_games_count = df[df[\"Moves\"].apply(lambda x: len(x.split()) < 12)].shape[0]\nprint(f\"Games with less than 12 moves: {short_move_games_count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.872889Z","iopub.execute_input":"2025-03-21T14:40:26.873155Z","iopub.status.idle":"2025-03-21T14:40:26.913084Z","shell.execute_reply.started":"2025-03-21T14:40:26.873133Z","shell.execute_reply":"2025-03-21T14:40:26.912186Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_copy = df.copy()\nlen(df_copy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.914056Z","iopub.execute_input":"2025-03-21T14:40:26.914393Z","iopub.status.idle":"2025-03-21T14:40:26.920352Z","shell.execute_reply.started":"2025-03-21T14:40:26.914354Z","shell.execute_reply":"2025-03-21T14:40:26.919592Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n **Data Cleaning**:\n   - **Remove Unknown Openings**: Drops rows where the \"Opening\" column is `\"?\"`.\n   - **Remove Short Games**: Drops games with fewer than 12 moves.\n","metadata":{}},{"cell_type":"code","source":"# Drop rows with unknown openings\ndf_clean = df_copy[df_copy[\"Opening\"] != \"?\"]\n\n# Drop games with less than 10 moves (e.g. weird games or aborted)\ndf_clean = df_clean[df_clean[\"Moves\"].apply(lambda x: len(x.split()) >= 12)]\n\nprint(f\"Remaining games after cleaning: {len(df_clean)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.921186Z","iopub.execute_input":"2025-03-21T14:40:26.921426Z","iopub.status.idle":"2025-03-21T14:40:26.965121Z","shell.execute_reply.started":"2025-03-21T14:40:26.921407Z","shell.execute_reply":"2025-03-21T14:40:26.964514Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n3. **Result Conversion**:\n   - Converts the game result into binary values: `1` for a White win, `1` for a Black win, and `0` for a draw.\n","metadata":{}},{"cell_type":"code","source":"def result_to_binary(result):\n    if result == \"1-0\":\n        return 1, 0\n    elif result == \"0-1\":\n        return 0, 1\n    else:  # \"1/2-1/2\" or others\n        return 0, 0\n\ndf_clean[\"White_Win\"], df_clean[\"Black_Win\"] = zip(*df_clean[\"Result\"].map(result_to_binary))\n\n# Quick check\nprint(df_clean[[\"Result\", \"White_Win\", \"Black_Win\"]].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.968068Z","iopub.execute_input":"2025-03-21T14:40:26.968269Z","iopub.status.idle":"2025-03-21T14:40:26.987734Z","shell.execute_reply.started":"2025-03-21T14:40:26.968252Z","shell.execute_reply":"2025-03-21T14:40:26.987037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n5. **Final Data**:\n   - The cleaned DataFrame is stored in `df_clean` with new columns for `White_Win` and `Black_Win`","metadata":{}},{"cell_type":"code","source":"df_clean.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:26.989054Z","iopub.execute_input":"2025-03-21T14:40:26.989271Z","iopub.status.idle":"2025-03-21T14:40:27.007512Z","shell.execute_reply.started":"2025-03-21T14:40:26.989252Z","shell.execute_reply":"2025-03-21T14:40:27.006640Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The `split_moves` function splits a sequence of chess moves into separate lists for White and Black, based on even and odd indices.\n","metadata":{}},{"cell_type":"code","source":"def split_moves(moves_sequence):\n    \"\"\"Splits a sequence of chess moves into separate lists for White and Black.\"\"\"\n    moves = moves_sequence.split()  # Split by spaces\n    white_moves = moves[0::2]  # Even indices (White's moves)\n    black_moves = moves[1::2]  # Odd indices (Black's moves)\n    return white_moves, black_moves\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:27.008241Z","iopub.execute_input":"2025-03-21T14:40:27.008476Z","iopub.status.idle":"2025-03-21T14:40:27.019870Z","shell.execute_reply.started":"2025-03-21T14:40:27.008458Z","shell.execute_reply":"2025-03-21T14:40:27.018996Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Apply function to split moves\ndf_clean[\"White Moves\"], df_clean[\"Black Moves\"] = zip(*df_clean[\"Moves\"].apply(split_moves))\n\n# Display the transformed data\nprint(df_clean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:27.020733Z","iopub.execute_input":"2025-03-21T14:40:27.021023Z","iopub.status.idle":"2025-03-21T14:40:27.191432Z","shell.execute_reply.started":"2025-03-21T14:40:27.020993Z","shell.execute_reply":"2025-03-21T14:40:27.190629Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Preparation for Tensors","metadata":{}},{"cell_type":"code","source":"df_clean[\"MoveList\"] = df_clean.apply(lambda row: [mv for pair in zip(row[\"White Moves\"], row[\"Black Moves\"]) for mv in pair if mv], axis=1)\ndf_clean.drop(\"Moves\",axis=1, inplace=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:27.192278Z","iopub.execute_input":"2025-03-21T14:40:27.192552Z","iopub.status.idle":"2025-03-21T14:40:27.347525Z","shell.execute_reply.started":"2025-03-21T14:40:27.192526Z","shell.execute_reply":"2025-03-21T14:40:27.346843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nimport torch\n\n# Extract move sequences\nall_move_seqs = df_clean[\"MoveList\"].tolist()\n\n# Flatten to get full move vocabulary\nall_moves = [move for seq in all_move_seqs for move in seq]\n\n# Encode moves\nencoder = LabelEncoder()\nencoder.fit(all_moves)\n\n# Transform move sequences\nencoded_seqs = [encoder.transform(seq) for seq in all_move_seqs]\n\n# Sliding window dataset\nseq_len = 10  # First 10 to predict the 11th\nX, y = [], []\nfor seq in encoded_seqs:\n    if len(seq) <= seq_len:\n        continue\n    for i in range(seq_len, len(seq)):\n        X.append(seq[i - seq_len:i])\n        y.append(seq[i])\n\n\n# Creating a tensor from a list of numpy.ndarrays is extremely slow\nX_np = np.array(X)\ny_np = np.array(y)\n\n# Final tensors\nX_tensor = torch.tensor(X_np, dtype=torch.long)\ny_tensor = torch.tensor(y_np, dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:27.348277Z","iopub.execute_input":"2025-03-21T14:40:27.348564Z","iopub.status.idle":"2025-03-21T14:40:46.001967Z","shell.execute_reply.started":"2025-03-21T14:40:27.348542Z","shell.execute_reply":"2025-03-21T14:40:46.001234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"X shape:\", X_tensor.shape)\nprint(\"y shape:\", y_tensor.shape)\n\nprint(\"X dtype:\", X_tensor.dtype)\nprint(\"y dtype:\", y_tensor.dtype)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:46.002793Z","iopub.execute_input":"2025-03-21T14:40:46.003264Z","iopub.status.idle":"2025-03-21T14:40:46.009182Z","shell.execute_reply.started":"2025-03-21T14:40:46.003229Z","shell.execute_reply":"2025-03-21T14:40:46.008503Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Print first few samples","metadata":{}},{"cell_type":"code","source":"print(\"First input sequence (token IDs):\", X_tensor[0])\nprint(\"First target move (token ID):\", y_tensor[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:46.010043Z","iopub.execute_input":"2025-03-21T14:40:46.010354Z","iopub.status.idle":"2025-03-21T14:40:46.042625Z","shell.execute_reply.started":"2025-03-21T14:40:46.010303Z","shell.execute_reply":"2025-03-21T14:40:46.042005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"If we want to decode back to UCI move for sanity Check","metadata":{}},{"cell_type":"code","source":"decoded_input = encoder.inverse_transform(X_tensor[0].numpy())\ndecoded_target = encoder.inverse_transform([y_tensor[0].item()])\n\nprint(\"Decoded input:\", decoded_input)\nprint(\"Decoded target:\", decoded_target[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:46.043238Z","iopub.execute_input":"2025-03-21T14:40:46.043463Z","iopub.status.idle":"2025-03-21T14:40:46.051831Z","shell.execute_reply.started":"2025-03-21T14:40:46.043444Z","shell.execute_reply":"2025-03-21T14:40:46.050956Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Value Ranges","metadata":{}},{"cell_type":"code","source":"print(\"Min token ID:\", X_tensor.min().item())\nprint(\"Max token ID:\", X_tensor.max().item())\nprint(\"Vocabulary size:\", len(encoder.classes_))  # Total unique moves\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:46.052688Z","iopub.execute_input":"2025-03-21T14:40:46.052920Z","iopub.status.idle":"2025-03-21T14:40:46.071931Z","shell.execute_reply.started":"2025-03-21T14:40:46.052890Z","shell.execute_reply":"2025-03-21T14:40:46.071188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distribution of Targets and Labels","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nunique, counts = torch.unique(y_tensor, return_counts=True)\nplt.bar(unique.numpy(), counts.numpy())\nplt.title(\"Distribution of Target Move Tokens\")\nplt.xlabel(\"Move Token ID\")\nplt.ylabel(\"Frequency\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:46.072897Z","iopub.execute_input":"2025-03-21T14:40:46.073181Z","iopub.status.idle":"2025-03-21T14:40:48.775215Z","shell.execute_reply.started":"2025-03-21T14:40:46.073154Z","shell.execute_reply":"2025-03-21T14:40:48.774362Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Building our first Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\nclass MoveRNN(nn.Module):\n    def __init__(self, vocab_size, embed_dim=128, hidden_dim=256):\n        super(MoveRNN, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n\n    def forward(self, x):\n        # x: [batch_size, seq_len]\n        x = self.embedding(x)           # -> [batch, seq_len, embed_dim]\n        output, _ = self.lstm(x)        # -> [batch, seq_len, hidden_dim]\n        last_hidden = output[:, -1, :]  # -> [batch, hidden_dim]\n        return self.fc(last_hidden)     # -> [batch, vocab_size]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:48.776156Z","iopub.execute_input":"2025-03-21T14:40:48.776526Z","iopub.status.idle":"2025-03-21T14:40:48.781612Z","shell.execute_reply.started":"2025-03-21T14:40:48.776491Z","shell.execute_reply":"2025-03-21T14:40:48.780896Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Training Loop","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader\nimport torch.optim as optim\n\n# Prepare DataLoader\nbatch_size = 64\ndataset = TensorDataset(X_tensor, y_tensor)\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Model init\nvocab_size = len(encoder.classes_)\nmodel = MoveRNN(vocab_size)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Loss & Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\nepochs = 10\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n    for X_batch, y_batch in dataloader:\n        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n\n        optimizer.zero_grad()\n        output = model(X_batch)              # [batch, vocab_size]\n        loss = criterion(output, y_batch)    # classification loss\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:40:48.782551Z","iopub.execute_input":"2025-03-21T14:40:48.782784Z","iopub.status.idle":"2025-03-21T14:45:16.306783Z","shell.execute_reply.started":"2025-03-21T14:40:48.782752Z","shell.execute_reply":"2025-03-21T14:45:16.305811Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" ### Quick Evaluation after Training","metadata":{}},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    sample_input = X_tensor[0].unsqueeze(0).to(device)  # [1, 10]\n    prediction = model(sample_input)                    # [1, vocab_size]\n    predicted_index = prediction.argmax(dim=1).item()\n    predicted_move = encoder.inverse_transform([predicted_index])[0]\n\n    print(\"Input Moves:\", encoder.inverse_transform(X_tensor[0].numpy()))\n    print(\"Target Move:\", encoder.inverse_transform([y_tensor[0].item()])[0])\n    print(\"Predicted Move:\", predicted_move)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:45:16.307852Z","iopub.execute_input":"2025-03-21T14:45:16.308278Z","iopub.status.idle":"2025-03-21T14:45:16.363223Z","shell.execute_reply.started":"2025-03-21T14:45:16.308254Z","shell.execute_reply":"2025-03-21T14:45:16.362581Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"So our model predicts moves. However these moves are not legal moves. Hence we need to ","metadata":{}},{"cell_type":"code","source":"import chess\n\n# Reconstruct board from input moves\ninput_moves = encoder.inverse_transform(X_tensor[0].numpy())\nboard = chess.Board()\nfor move in input_moves:\n    try:\n        board.push_san(move)\n    except:\n        print(f\"Illegal move in input: {move}\")\n        break\n\n# Get all legal UCI moves\nlegal_uci = [move.uci() for move in board.legal_moves]\nlegal_tokens = encoder.transform([m for m in legal_uci if m in encoder.classes_])\n\n# Mask prediction output\nwith torch.no_grad():\n    sample_input = X_tensor[0].unsqueeze(0).to(device)\n    logits = model(sample_input)[0]  # [vocab_size]\n    logits_filtered = logits[legal_tokens]\n    top_index = legal_tokens[logits_filtered.argmax().item()]\n    predicted_move = encoder.inverse_transform([top_index])[0]\n\n    print(\"Input Moves:\", encoder.inverse_transform(X_tensor[0].numpy()))\n    print(\"Target Move:\", encoder.inverse_transform([y_tensor[0].item()])[0])\n    print(\"Predicted Move:\", predicted_move)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-21T14:46:16.998668Z","iopub.execute_input":"2025-03-21T14:46:16.998946Z","iopub.status.idle":"2025-03-21T14:46:17.013234Z","shell.execute_reply.started":"2025-03-21T14:46:16.998926Z","shell.execute_reply":"2025-03-21T14:46:17.012361Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Summary**\nThe code above, is now able to predict moves based on first 10 moves. And these moves are legal moves. GOOD \nHowever we need to do reinforcement learning so that it predicts moves that are actually good. Not based on the data it was trained on.","metadata":{}}]}